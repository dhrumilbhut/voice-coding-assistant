# ğŸ¤ Voice Coding Assistant

> Transform your voice into code with AI-powered development assistance

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-green.svg)](https://openai.com)


A sophisticated voice-controlled coding assistant that leverages OpenAI's GPT models to help developers create, analyze, and manage code through natural speech interaction. Simply speak your requirements, and watch as complete projects come to life!


## âœ¨ Features

- ğŸ™ï¸ **Voice-to-Code**: Convert speech directly into functional code
- ğŸ”Š **Text-to-Speech**: AI responses spoken aloud with OpenAI's streaming TTS
- ğŸ¤– **AI-Powered**: Integrates with OpenAI GPT-4o-mini for intelligent responses
- ğŸ¯ **Model Selection**: Users can choose from multiple OpenAI models (gpt-4o-mini, gpt-4o, gpt-3.5-turbo) based on their cost/performance needs
- ğŸ—ï¸ **Hybrid Architecture**: Both Simple REST API and True MCP Protocol support
- ğŸ“ **Smart Project Organization**: Automatically creates organized project folders in `ai_projects/`
- ğŸ—‚ï¸ **Custom Locations**: Users can specify project locations - "Create in my_workspace folder"
- ğŸ› ï¸ **Multi-Tool Support**: File creation, code analysis, command execution
- ğŸ§  **Chain-of-Thought Reasoning**: Multi-step planning for complex tasks
- ğŸŒ **Web Development Ready**: Instant HTML, CSS, JavaScript project scaffolding
- ğŸ **Python Support**: Create and analyze Python projects
- ğŸ“ **Structured Outputs**: Reliable JSON-based AI responses
- ğŸ›¡ï¸ **Rate Limiting**: Prevents abuse and controls API costs by limiting requests per user/IP
- ğŸ”‘ **User-Provided OpenAI API Key**: Each user must supply their own OpenAI API key for every request, ensuring privacy and cost control
- ğŸ”Œ **True MCP Server**: Full JSON-RPC 2.0 compliant Model Context Protocol implementation
- ğŸ“Š **Multi-Tenant Ready**: Supports multiple users with isolated API usage and billing
- ğŸ§© **Easy Integration**: Ready for use with external tools, scripts, or future VS Code extension

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key
- Microphone (optional - works in text mode too)


### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/voice-coding-assistant.git
   cd voice-coding-assistant
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables (CLI only)**
   ```bash
   cp .env.example .env
   # Edit .env and add your OpenAI API key (for CLI mode only)
   ```

4. **Run the assistant (CLI mode)**
   ```bash
   python main.py
   ```

5. **ğŸ”¥ Run Hybrid Mode (Recommended)**
   ```bash
   python hybrid_server.py
   ```
   *Starts both Simple REST API (8000) and MCP Server (8001)*

6. **Or run individually:**
   ```bash
   # Simple REST API only
   uvicorn server:app --reload
   
   # MCP Server only  
   python mcp_server.py
   ```

7. **ğŸ§ª Test the APIs**
   ```bash
   python test_apis.py
   ```


## ğŸ¯ Usage Examples

### CLI Mode
Run `python main.py` for interactive voice/text coding assistance.

### Simple REST API

Send a POST request to `/api/ask`:

<details>
<summary>ğŸ“‹ Click to view REST API curl example</summary>

```bash
curl -X POST "http://127.0.0.1:8000/api/ask" \
   -H "Content-Type: application/json" \
   -d '{
      "user_input": "Create a Python function to add two numbers",
      "api_key": "sk-...your-openai-key...",
      "model": "gpt-4o-mini",
      "context": {}
   }'
```

</details>



**ğŸ¯ Model Selection**: Users can specify which OpenAI model to use by including a `"model"` parameter. Defaults to `"gpt-4o-mini"` if not specified.

### True MCP (Model Context Protocol) Server

The project includes a **real MCP-compliant server** following the JSON-RPC 2.0 protocol:

<details>
<summary>ğŸ”Œ 1. Initialize the MCP connection</summary>

```bash
curl -X POST "http://127.0.0.1:8001/mcp/rpc" \
   -H "Content-Type: application/json" \
   -d '{
      "jsonrpc": "2.0",
      "id": 1,
      "method": "initialize",
      "params": {
         "protocolVersion": "2024-11-05",
         "capabilities": {"tools": {}},
         "clientInfo": {"name": "my-client", "version": "1.0.0"}
      }
   }'
```

</details>

<details>
<summary>ğŸ› ï¸ 2. List available tools</summary>

```bash
curl -X POST "http://127.0.0.1:8001/mcp/rpc" \
   -H "Content-Type: application/json" \
   -d '{
      "jsonrpc": "2.0",
      "id": 2,
      "method": "tools/list"
   }'
```

</details>

<details>
<summary>âš¡ 3. Call a tool</summary>

```bash
curl -X POST "http://127.0.0.1:8001/mcp/rpc" \
   -H "Content-Type: application/json" \
   -d '{
      "jsonrpc": "2.0",
      "id": 3,
      "method": "tools/call",
      "params": {
         "name": "create_file",
         "arguments": {
            "file_path": "hello.py",
            "content": "print(\"Hello MCP!\")",
            "api_key": "sk-...your-key..."
         }
      }
   }'
```

</details>

<details>
<summary>ğŸ¤– 4. Use the AI assistant</summary>

```bash
curl -X POST "http://127.0.0.1:8001/mcp/rpc" \
   -H "Content-Type: application/json" \
   -d '{
      "jsonrpc": "2.0",
      "id": 4,
      "method": "assistant/ask",
      "params": {
         "user_input": "Create a todo app",
         "api_key": "sk-...your-key...",
         "model": "gpt-4o-mini",
         "context": {}
      }
   }'
```

</details>

**ğŸ¯ Model Selection**: Both APIs support user-selectable models via the `"model"` parameter. This allows API key owners to control cost and performance trade-offs.

**Note:** Each request must include a valid OpenAI API key. The simple API is rate-limited (10/minute), while MCP allows 30/minute for more complex workflows.

### Create a Todo App
```
ğŸ¤ "Create a todo app with HTML, CSS, and JavaScript"
```
**Result**: Complete todo application in `ai_projects/todo_app/` folder with:
- `index.html` - Responsive HTML structure
- `style.css` - Modern CSS styling  
- `script.js` - Interactive JavaScript functionality

### Create with Custom Location
```
ğŸ¤ "Create a calculator app in my_projects folder"
```
**Result**: Calculator application in `my_projects/calculator_app/` folder

### Analyze Code
```
ğŸ¤ "Analyze the main.py file"
```
**Result**: Detailed code analysis with metrics and insights

### Build a Calculator
```
ğŸ¤ "Create a calculator app"
```
**Result**: Functional calculator in `calculator_app/` folder


## ğŸ“‚ Project Structure

```
voice-coding-assistant/
â”œâ”€â”€ main.py              # Main application entry point (CLI)
â”œâ”€â”€ assistant_core.py    # Core assistant logic (shared by CLI and APIs)
â”œâ”€â”€ server.py            # Simple REST API server
â”œâ”€â”€ mcp_server.py        # True MCP-compliant JSON-RPC server
â”œâ”€â”€ hybrid_server.py     # Runs both APIs simultaneously  
â”œâ”€â”€ tools.py             # Tool functions (file ops, analysis)
â”œâ”€â”€ test_apis.py         # Example usage for both APIs
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env.example         # Environment variables template
â”œâ”€â”€ README.md            # This file
â””â”€â”€ ai_projects/         # Organized AI-generated projects
   â”œâ”€â”€ todo_app/
   â”œâ”€â”€ calculator_app/
   â”œâ”€â”€ web_app/
   â”œâ”€â”€ game_app/
   â””â”€â”€ python_project/
```

## ğŸ› ï¸ Available Tools

| Tool | Description | Example Use |
|------|-------------|-------------|
| `create_file` | Create new files with content | Building HTML, CSS, JS files |
| `read_file` | Read existing file contents | Code review and analysis |
| `write_file` | Update existing files | Modifying configurations |
| `analyze_code` | Analyze code structure | Getting code metrics |
| `run_command` | Execute system commands | Git operations, builds |

## ğŸ¨ Smart Project Detection & Custom Locations

The assistant automatically detects project types and creates organized folders in `ai_projects/`:

| Project Type | Keywords | Default Folder | Custom Location Example |
|--------------|----------|----------------|------------------------|
| ğŸ“ Todo Apps | todo, task, checklist | `ai_projects/todo_app/` | `my_workspace/todo_app/` |
| ğŸ§® Calculator | calc, calculator, math | `ai_projects/calculator_app/` | `desktop/tools/calculator_app/` |
| ğŸŒ¤ï¸ Weather Apps | weather, forecast | `ai_projects/weather_app/` | `projects/weather_app/` |
| ğŸ’¼ Portfolio | portfolio, resume, cv | `ai_projects/portfolio_app/` | `websites/portfolio_app/` |
| ğŸ›’ E-commerce | shop, store, cart | `ai_projects/ecommerce_app/` | `business/ecommerce_app/` |
| ğŸ® Games | game, puzzle, play | `ai_projects/game_app/` | `my_games/game_app/` |
| ğŸŒ Web Apps | General HTML/CSS/JS | `ai_projects/web_app/` | `webdev/web_app/` |
| ğŸ Python | Python files | `ai_projects/python_project/` | `scripts/python_project/` |

### ğŸ—‚ï¸ **Custom Location Examples**

Users can specify custom locations using natural language:

```bash
ğŸ¤ "Create a todo app in my_projects folder"
ğŸ“ Result: my_projects/todo_app/

ğŸ¤ "Put the calculator in desktop/tools"
ğŸ“ Result: desktop/tools/calculator_app/

ğŸ¤ "Save in location: custom_workspace"
ğŸ“ Result: custom_workspace/[detected_project_type]/

ğŸ¤ "Create in directory: user_apps"  
ğŸ“ Result: user_apps/[detected_project_type]/
```

### ğŸ¯ **Location Detection Patterns**
The system recognizes various ways users specify custom locations:
- "Create ... in [folder]"
- "Put ... in [folder]"
- "Save in location: [folder]"
- "Create in directory: [folder]"
- "Location: [folder]"
- "Folder: [folder]"

## ğŸ—ï¸ **Hybrid Architecture Overview**

```
ğŸ¤ Voice Coding Assistant - Hybrid Architecture
â”œâ”€â”€ ğŸ“¡ Simple REST API (Port 8000)     â”œâ”€â”€ ğŸ”Œ MCP Server (Port 8001)
â”‚   â”œâ”€â”€ POST /api/ask                  â”‚   â”œâ”€â”€ JSON-RPC 2.0 Protocol
â”‚   â”œâ”€â”€ Rate Limit: 10/min             â”‚   â”œâ”€â”€ Rate Limit: 30/min
â”‚   â””â”€â”€ Perfect for MVPs               â”‚   â””â”€â”€ Standards Compliant
â”‚                                      â”‚
â””â”€â”€ ğŸ§  Shared Core Logic (assistant_core.py)
    â”œâ”€â”€ OpenAI GPT Integration
    â”œâ”€â”€ Chain-of-Thought Reasoning
    â”œâ”€â”€ Tool Execution Engine
    â””â”€â”€ Project Organization
```

### ğŸ¯ **Why Hybrid Approach?**
- **ğŸš€ Speed**: Simple REST for quick integrations and testing
- **ğŸ“ Standards**: MCP compliance for future-proof AI ecosystem integration
- **ğŸ”„ Flexibility**: Developers choose what fits their workflow
- **ğŸ’¡ Innovation**: Best of both worlds without compromise

## ğŸ”§ Configuration

### API Comparison

| Feature | Simple REST API | True MCP Server |
|---------|----------------|-----------------|
| **Protocol** | HTTP REST | JSON-RPC 2.0 |
| **Port** | 8000 | 8001 |
| **Endpoint** | `/api/ask` | `/mcp/rpc` |
| **Rate Limit** | 10/minute | 30/minute |
| **Initialization** | None required | MCP handshake required |
| **Tool Discovery** | Not available | `/tools/list` method |
| **Compliance** | Simple & fast | MCP standard compliant |
| **Use Case** | Quick integration | Standard MCP clients |

### Environment Variables

For CLI mode, create a `.env` file with:

```env
# Required for CLI
OPENAI_API_KEY=your_openai_api_key_here
```

For API mode, each request must include an `api_key` field with a valid OpenAI API key. The `.env` file is not required for API usage.

### Supported Models

- `gpt-4o-mini` (default) - Fast and cost-effective, optimal for most coding tasks
- `gpt-4o` - More capable for complex architectural decisions and advanced coding
- `gpt-3.5-turbo` - Budget-friendly option for simple tasks
- `gpt-4` - Legacy model, more expensive but highly capable

**ğŸ¯ Model Selection**: Users can choose models based on their specific needs:
- **Cost-conscious**: Use `gpt-4o-mini` for routine coding tasks
- **Performance-critical**: Use `gpt-4o` for complex problem-solving
- **Budget-limited**: Use `gpt-3.5-turbo` for simple file generation

Since users provide their own API keys, they control the cost/performance trade-off!

## ğŸ§  How It Works

The assistant uses a structured reasoning approach:

1. **ğŸ”¥ START**: Processes your voice/text input
2. **ğŸ§  PLAN**: Creates multi-step execution plan
3. **ğŸ› ï¸ TOOL**: Executes necessary tools (file creation, analysis)
4. **ğŸ‘ï¸ OBSERVE**: Reviews tool outputs
5. **ğŸ¤– OUTPUT**: Provides final response

### Example Workflow

```
ğŸ¤ Input: "Create a landing page for a coffee shop"

ğŸ§  Planning: "User wants a coffee shop landing page"
ğŸ§  Planning: "I'll create HTML structure with header, menu, contact"
ğŸ§  Planning: "Add CSS for warm, coffee-themed styling"
ğŸ§  Planning: "Include JavaScript for interactive menu"

ğŸ› ï¸ Tool: create_file(index.html, [HTML content])
ğŸ› ï¸ Tool: create_file(style.css, [CSS content])  
ğŸ› ï¸ Tool: create_file(script.js, [JS content])

ğŸ¤– Output: "Created a complete coffee shop landing page!"
```

---

<div align="center">

**Made with â¤ï¸ by Dhrumil Bhut**

[â­ Star this repo](https://github.com/dhrumilbhut/voice-coding-assistant) if you find it helpful!

</div>